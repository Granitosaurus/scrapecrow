<!DOCTYPE html>
<html lang="en">

<head>
  <title> Scrapecrow - Web Scraping Target Discovery: Sitemaps</title>
  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="description" content="Educational blog about web-scraping, crawling and related data extraction subjects" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css"
    integrity="sha256-XoaMnoYC5TH6/+ihMEnospgm0J1PM/nioxbOUdnM8HY=" crossorigin="anonymous">
  <script src="https://scrapecrow.com/theme/main.js"></script>
  <link rel="stylesheet" href="https://scrapecrow.com/theme/css/main.css" />
  <link rel="stylesheet" href="https://scrapecrow.com/theme/css/applause-button.css" />
  <script src="https://scrapecrow.com/theme/applause-button.js"></script>
  <link href="Scrapecrow/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
    title="Scrapecrow Full Atom Feed" />
  <link href="Scrapecrow/atom.xml" type="application/atom+xml" rel="alternate"
    title="Scrapecrow Atom Feed" />
  <link href="Scrapecrow/rss.xml" type="application/rss+xml" rel="alternate"
    title="Scrapecrow RSS Feed" />
  <link href="Scrapecrow/feeds/{slug}.atom.xml" type="application/atom+xml"
    rel="alternate" title="Scrapecrow Categories Atom Feed" />

<meta name="author" content="Bernardas Ališauskas" />
<meta name="description" content="There are many techniques when it comes to discovery web-scraping targets. One of the most common ones is to use website sitemap indexes. What are they and to take advantage of them in web-scraping?" />
  <meta property="og:site_name" content="Scrapecrow"/>
  <meta property="og:title" content="Web Scraping Target Discovery: Sitemaps"/>
  <meta property="og:description" content="There are many techniques when it comes to discovery web-scraping targets. One of the most common ones is to use website sitemap indexes. What are they and to take advantage of them in web-scraping?"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:url" content="https://scrapecrow.com/web-scraping-discovery-sitemaps.html"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="2021-09-28 00:00:00+02:00"/>
  <meta property="article:modified_time" content="2021-09-28 00:00:00+02:00"/>
  <meta property="article:author" content="Bernardas Ališauskas">
  <meta property="article:section" content="articles"/>
  <meta property="article:tag" content="discovery"/>
  <meta property="article:tag" content="discovery-methods"/>
  <meta property="article:tag" content="sitemap"/>
  <meta property="article:tag" content="intermediate"/>
  <meta property="og:image" content="https://scrapecrow.com/images/logo-og.png">
</head>

<body>
  <div class="navigation">
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a class="navbar-item" href="https://scrapecrow.com">
          <img src="/images/logo.svg" width="50"></img>
        </a>
        <a class="navbar-item" href="https://scrapecrow.com">Scrapecrow</a>
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu" id="navMenu">
        <div class="navbar-start">
          <a class="navbar-item" href="/pages/about.html">about</a>
          <a class="navbar-item" href="/pages/hire.html">hire</a>
          <a class="navbar-item" href="/pages/coffee.html">☕</a>
          <a class="navbar-item" href="https://matrix.to/#/#web-scraping:matrix.org">#web-scraping on matrix</a>
        </div>
      </div>
    </nav>
  </div>
  <div class="main">
<div class="content">
  <div class="post-meta">
<div class="post-meta">
    <a href="https://scrapecrow.com/category/articles.html" class="category">articles</a>
    &mdash;
    <span title="2021-09-28T00:00:00+02:00">Tue 28 September 2021</span></br>
    <a class="tag" href="https://scrapecrow.com/tag/discovery.html" title="finding content on a website">discovery</a>
    <a class="tag" href="https://scrapecrow.com/tag/discovery-methods.html" title="ways to discover content on a website">discovery-methods</a>
    <a class="tag" href="https://scrapecrow.com/tag/sitemap.html" title="website content index specifically designed for web scrapers">sitemap</a>
    <a class="tag" href="https://scrapecrow.com/tag/intermediate.html" title="intermediate level article">intermediate</a>
    </br>
</div>  </div>
  <h1>Web Scraping Target Discovery: Sitemaps</h1>
  <div class="post-content">
    <!--insert table of contents between text and first header-->
    <p><a href="/images/banner-map.jpg"><img class="fullc" loading="lazy" src="/images/banner-map.jpg" title=""/></a><figcaption></figcaption></p>
<p>Most web scrapers are made up of two core parts: finding products on the website and actually scraping them. The former is often referred to as "target discovery" step. For example to scrape product data of an e-commerce website we would need to find urls to each individual product and only then we can scrape their data.</p>
<p>Discovering targets to scrape in web scraping is often a challenging and important task. This series of blog posts tagged with <a href="/tag/discovery-methods.html">#discovery-methods</a> (also see <a href="/web-scraping-discovery.html">main article</a>) covers common target discovery approaches.</p>
<p>In this article will cover one particular discovery method of using website sitemaps to find our scrape targets.</p>

    <hr>
    <div class="pure-u">
      <div id="toc"><ul><li><a class="toc-href" href="#what-are-sitemaps-and-how-are-they-used-in-web-scraping" title="What are sitemaps and how are they used in web-scraping?">What are sitemaps and how are they used in web-scraping?</a></li><li><a class="toc-href" href="#finding-sitemaps" title="Finding Sitemaps">Finding Sitemaps</a></li><li><a class="toc-href" href="#example-use-case-hmcom" title="Example Use Case: HM.com">Example Use Case: HM.com</a></li><li><a class="toc-href" href="#confirming-results" title="Confirming Results">Confirming Results</a></li><li><a class="toc-href" href="#summary-and-further-reading" title="Summary and Further Reading">Summary and Further Reading</a></li></ul></div>
    </div>
    <hr>
    <h2 id="what-are-sitemaps-and-how-are-they-used-in-web-scraping">What are sitemaps and how are they used in web-scraping?</h2>
<p>Sitemap is an index document generated by websites for web crawlers and indexers. For example websites that want to be crawled by google provide an index of their products so Google's crawlers can index it quicker. </p>
<p>To put it shortly sitemap files are always of xml type (often gzip compressed) documents that contain URL locations and some meta information about them:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="cp">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="nt">&lt;urlset</span> <span class="na">xmlns=</span><span class="s">"http://www.sitemaps.org/schemas/sitemap/0.9"</span><span class="nt">&gt;</span>
   <span class="nt">&lt;url&gt;</span>
      <span class="nt">&lt;loc&gt;</span>http://www.example.com/<span class="nt">&lt;/loc&gt;</span>
      <span class="nt">&lt;lastmod&gt;</span>2005-01-01<span class="nt">&lt;/lastmod&gt;</span>
      <span class="nt">&lt;changefreq&gt;</span>monthly<span class="nt">&lt;/changefreq&gt;</span>
      <span class="nt">&lt;priority&gt;</span>0.8<span class="nt">&lt;/priority&gt;</span>
   <span class="nt">&lt;/url&gt;</span>
<span class="nt">&lt;/urlset&gt;</span> 
</code></pre></div>
</td></tr></table>
<p class="info">for more on sitemap structure rules, see <a href="https://www.sitemaps.org/protocol.html">official specification page</a></p>
<p>The documents themselves are usually categorized by names, so for example:   </p>
<ul>
<li>blog post of the website would be contained in <code>sitemap_blogs.xml</code>.   </li>
<li>Sold products might be separated in multiple files of <code>sitemap_products_1.xml</code>, <code>sitemap_products_2.xml</code> etc  </li>
</ul>
<p>Before using sitemaps a web scraping discovery strategy, it's a good practice to reflect on common pros and cons of this technique and see whether that would fit your web-scraping project:</p>
<p>Pros:  </p>
<ul>
<li><strong>Efficiency</strong>: Single sitemap can contain thousands of items and often entire catalog can be discovered in just few requests!   </li>
<li><strong>Simplicity</strong>: There's no need for advanced reverse engineering knowledge to use sitemap based discovery.  </li>
</ul>
<p>Cons:  </p>
<ul>
<li><strong>Data Staleness</strong>: Sitemap indexes need to be generated by the website explicitly and sometimes newer product might not appear on the index for significant amount of time.  </li>
<li><strong>Data Validity</strong>: As per previous point because of sitemap staleness some product links might be expired or invalidated. This might cause unnecessary load on your scraper.</li>
<li><strong>Data Completeness</strong>: Since sitemaps are generated for crawlers and indexers they might not have all data that is available on the website. For this reason it is important to confirm sitemap coverage during the development of a scraper.  </li>
<li><strong>Availability</strong>: Sitemaps is/used to be an important part of the web, particularly used in SEO however they are not always present in modern websites that either try to avoid web-scraping or use hard-to-index website structures or are just too big for such indexes.  </li>
<li><strong>Risk</strong>: Some website use sitemaps as honeypots for web-scrapers and direct to invalid data or use it to identify and ban scrapers.</li>
</ul>
<p>As you can see, Sitemaps discovery approach appears to be simple and efficient, though not always viable. Generally when developing discovery strategy, sitemaps is the first place I look for product data, then confirm quality by trying alternative discovery approaches and seeing if coverage matches. </p>
<h2 id="finding-sitemaps">Finding Sitemaps</h2>
<p>To take advantage of sitemaps, we first need to figure how to find them. Common way to find sitemaps is checking <code>robots.txt</code> or <code>sitemaps.xml</code> file.<br/>
For example, let's take popular clothing shop <code>hm.com</code>:</p>
<p>First we would go to <code>/robots.txt</code> page: <a href="https://hm.com/robots.txt">https://hm.com/robots.txt</a>:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>User-Agent: *
Request-rate: 2/1 0000-0200
Request-rate: 1/2 0200-0900
Disallow: /alive/user
Disallow: /m/
...
Sitemap: http://www2.hm.com/sitemapindex.xml
</code></pre></div>
</td></tr></table>
<p>We see some robot scraping rules and a link to the sitemap index! If we proceed and take a look at the sitemap index <a href="http://www2.hm.com/sitemapindex.xml">http://www2.hm.com/sitemapindex.xml</a> we can see:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>...
<span class="nt">&lt;sitemap&gt;</span>
    <span class="nt">&lt;loc&gt;</span>https://www2.hm.com/en_in.sitemap.xml<span class="nt">&lt;/loc&gt;</span>
    <span class="nt">&lt;lastmod&gt;</span>2021-09-29<span class="nt">&lt;/lastmod&gt;</span>
<span class="nt">&lt;/sitemap&gt;</span>
<span class="nt">&lt;sitemap&gt;</span>
    <span class="nt">&lt;loc&gt;</span>https://www2.hm.com/en_us.sitemap.xml<span class="nt">&lt;/loc&gt;</span>
    <span class="nt">&lt;lastmod&gt;</span>2021-09-29<span class="nt">&lt;/lastmod&gt;</span>
<span class="nt">&lt;/sitemap&gt;</span>
<span class="nt">&lt;sitemap&gt;</span>
    <span class="nt">&lt;loc&gt;</span>https://www2.hm.com/de_de.sitemap.xml<span class="nt">&lt;/loc&gt;</span>
    <span class="nt">&lt;lastmod&gt;</span>2021-09-29<span class="nt">&lt;/lastmod&gt;</span>
<span class="nt">&lt;/sitemap&gt;</span>
...
</code></pre></div>
</td></tr></table>
<p>The index is split into localized parts, let's continue to <code>en_us</code> index (or whichever you prefer, they should function the same): <a href="https://www2.hm.com/en_us.sitemap.xml">https://www2.hm.com/en_us.sitemap.xml</a></p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nt">&lt;sitemapindex</span> <span class="na">xmlns:xsi=</span><span class="s">"https://www.w3.org/2001/XMLSchema-instance"</span> <span class="na">xmlns=</span><span class="s">"https://www.sitemaps.org/schemas/sitemap/0.9"</span> <span class="na">xsi:schemaLocation=</span><span class="s">"https://www.sitemaps.org/schemas/sitemap/0.9 https://www.sitemaps.org/schemas/sitemap/0.9/siteindex.xsd"</span><span class="nt">&gt;</span>
<span class="nt">&lt;sitemap&gt;</span>
    <span class="nt">&lt;loc&gt;</span>https://www2.hm.com/en_us.pages.0.xml<span class="nt">&lt;/loc&gt;</span>
    <span class="nt">&lt;lastmod&gt;</span>2021-09-29<span class="nt">&lt;/lastmod&gt;</span>
<span class="nt">&lt;/sitemap&gt;</span>
<span class="nt">&lt;sitemap&gt;</span>
    <span class="nt">&lt;loc&gt;</span>https://www2.hm.com/en_us.store.0.xml<span class="nt">&lt;/loc&gt;</span>
    <span class="nt">&lt;lastmod&gt;</span>2021-09-29<span class="nt">&lt;/lastmod&gt;</span>
<span class="nt">&lt;/sitemap&gt;</span>
<span class="nt">&lt;sitemap&gt;</span>
    <span class="nt">&lt;loc&gt;</span>https://www2.hm.com/en_us.product.0.xml<span class="nt">&lt;/loc&gt;</span>
    <span class="nt">&lt;lastmod&gt;</span>2021-09-29<span class="nt">&lt;/lastmod&gt;</span>
<span class="nt">&lt;/sitemap&gt;</span>
<span class="nt">&lt;sitemap&gt;</span>
    <span class="nt">&lt;loc&gt;</span>https://www2.hm.com/en_us.product.1.xml<span class="nt">&lt;/loc&gt;</span>
    <span class="nt">&lt;lastmod&gt;</span>2021-09-29<span class="nt">&lt;/lastmod&gt;</span>
<span class="nt">&lt;/sitemap&gt;</span>
</code></pre></div>
</td></tr></table>
<p>This is index of sitemap indexes. We see there are indexes for articles, pages and categories etc. - but most importantly product index: <code>....products.N.xml</code>. <br/>
To add there's some important metadata as well: when indexes were last updated: <code>&lt;lastmod&gt;</code>. In this case the index is 1 day old so this discovery approach will not pick up any products that have been added in the last few hours.</p>
<p class="info">Every website engine generates sitemaps at different times: some generate once a day/week often indicated by <code>&lt;changefreq&gt;always|hourly|daily|...&lt;/changefreq&gt;</code> attribute. Though modern, smaller websites usually generate it on demand when product index is updated which is great for web-scrapers!</p>
<h2 id="example-use-case-hmcom">Example Use Case: HM.com</h2>
<p>Lets write a simple sitemap scraper that will find all product urls on previously mentioned website <a href="https://hm.com">https://hm.com</a>. For this we'll be using python with <code>requests</code> and <code>parsel</code> libraries:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1"># requires:</span>
<span class="c1"># pip install requests parsel</span>

<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">parsel</span> <span class="kn">import</span> <span class="n">Selector</span>


<span class="k">def</span> <span class="nf">parse_sitemap</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="sd">"""scrape sitemap and item urls from a sitemap link"""</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"scraping: </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
        <span class="n">url</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="p">{</span>
            <span class="c1"># we need to fake browser user-string to get through CDN bot protection</span>
            <span class="s2">"User-Agent"</span><span class="p">:</span> <span class="s2">"Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0"</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="c1"># turn html text to a parsable tree object</span>
    <span class="n">doc_tree</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
    <span class="c1"># find all &lt;loc&gt; nodes and take their text (which is an url)</span>
    <span class="n">urls</span> <span class="o">=</span> <span class="n">doc_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">"//loc/text()"</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">urls</span>


<span class="n">product_urls</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="n">sitemap_directory</span> <span class="o">=</span> <span class="s2">"https://www2.hm.com/en_us.sitemap.xml"</span>
<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">parse_sitemap</span><span class="p">(</span><span class="n">sitemap_directory</span><span class="p">):</span>
    <span class="k">if</span> <span class="s2">".product."</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">url</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">parse_sitemap</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
        <span class="c1"># product urls match pattern com/&lt;some product naming&gt;.html</span>
        <span class="c1"># skip non-product urls</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"hm.com/.+?\.html"</span><span class="p">,</span> <span class="n">url</span><span class="p">):</span>
            <span class="k">continue</span>
        <span class="n">product_urls</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">product_urls</span><span class="p">)[</span><span class="o">-</span><span class="mi">100</span><span class="p">:])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">product_urls</span><span class="p">))</span>
</code></pre></div>
</td></tr></table>
<p>If we run this small scraper script we'll see that this sitemap discovery approach will yield us 13639 unique results (at the time of writing)! Even if we scrape synchronously sitemap approach is a really efficient way to discover large amount of products.</p>
<h2 id="confirming-results">Confirming Results</h2>
<p>Finally we should confirm whether this discovery approach has good coverage by comparing it with other discovery approaches. For that we either need to find all product count number somewhere (some websites mention "total N results available" somewhere in their content) or use another discovery strategy to evaluate our coverage. For this particular website we can take a look at <a href="/web-scraping-discovery-search.html">search bar discovery approach</a> covered in other Scrapecrow article:</p>
<p><a href="/images/hm.com-space-search.png"><img class="bigc" loading="lazy" src="/images/hm.com-space-search.png" title="13780 results found by searching for url quote space character &lt;code&gt;%20&lt;/code&gt;"/></a><figcaption>13780 results found by searching for url quote space character <code>%20</code></figcaption></p>
<p>Using empty search approach described in <a href="/web-scraping-discovery-search.html">search discovery article</a> we can see that our sitemap discovery coverage showing almost the same amount of results:</p>
<ul>
<li>Sitemaps: 13639</li>
<li>Searchbar: 13780</li>
</ul>
<p>These 141 results we're missing are probably indication that sitemap index is running slightly behind the product database. This is a good illustration of different discovery techniques and their importance. For important scrapers it's a good idea to diversify.</p>
<h2 id="summary-and-further-reading">Summary and Further Reading</h2>
<p>To summarize using sitemaps in web scraping is an efficient, effective and quick product discovery technique with only real down-sides being data staleness, coverage and availability.</p>
<hr/>
<p>For more web-scraping discovery techniques, see <a href="/tag/discovery-methods.html">#discovery-methods</a> and <a href="/tag/discovery.html">#discovery</a> for more discovery related subjects.  </p>
<p>If you have any questions, come join us on <a href="https://matrix.to/#/%23web-scraping:matrix.org">#web-scraping on matrix</a>, check out <a href="https://stackoverflow.com/questions/tagged/web-scraping">#web-scraping on stackoverflow</a> or leave a comment below!  </p>
<p>As always, you can hire me for web-scraping consultation over at <a href="/pages/hire.html">hire</a> page and happy scraping!  </p>
<hr/>
<figcaption>image credits: "Map of North America" by NASA Johnson is licensed under CC BY-NC 2.0</figcaption>
  </div>
</div>
<hr>
<div class="article-buttons">
  <div class="float-side applause" title="show your appreciation">
    <applause-button url="https://scrapecrow.com/web-scraping-discovery-sitemaps.html" style="width: 58px; height: 58px;" />
  </div>
  <div class="article-button applause" title="show your appreciation">
    <applause-button url="https://scrapecrow.com/web-scraping-discovery-sitemaps.html" style="width: 58px; height: 58px;" />
  </div>
  <div class="article-button twitter" title="share on twitter">
    <a href="http://twitter.com/share?text=&url=https://scrapecrow.com/web-scraping-discovery-sitemaps.html&hashtags=">
      <i class="fa fa-twitter fa-3x pure-menu-link" aria-hidden="true"></i>
    </a>
  </div>
  <div class="article-button email">
    <a href="https://716df175.sibforms.com/serve/MUIEALpKPp8WjHrVwQOX6keZXLkJRbnFEh2y6YhTmVmT4Z0Khgbi2MFvPO1OObOrjbMi_S0M7VXkXGkcbh36H-SqEwM3dHXxdrOOXwEPGcp9rTQKkQvMkC70Dq9RmCoikia87nLsRcx0VVGmCG2zyx5s8BwpqevRmh70vKSaLe7e95yZDCROMvm2HcN3UpLw7UsFxl_UbI6TjY_e" title="subscribe to mailist">
      <i class="fa fa-email-bulk-o fa-3x pure-menu-link" aria-hidden="true"></i>
    </a>
  </div>
</div>
<hr>
<div class="comments">
  <script src="https://utteranc.es/client.js" repo="granitosaurus/scrapecrow"
    issue-term="web-scraping-discovery-sitemaps" label="comments"
    theme="github-light" crossorigin="anonymous" async>
  </script>
</div>
  </div>
  <footer class="footer">
    <div class="content">
      <span class="footer-item"><a href="/archives.html">Archives</a></span>
      <span class="footer-item"><a href="/tags.html">Tags</a></span>
      <span class="footer-item"><a href="https://blog.getpelican.com/">Made with Pelican</a></span>
      <span class="footer-item"><a href="https://github.com/granitosaurus/scrapecrow/">Source on Github</a></span>
      <span class="footer-item"><a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a></span>
      <span class="footer-item">
        <a href="atom.xml">
          <i class="fa fa-rss-square" aria-hidden="true"></i>
        </a>
      </span>
    </div>
  </footer>
<script data-goatcounter="https://scrapecrow.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
</body>

</html>